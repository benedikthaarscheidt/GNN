{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef7cdb-7fdf-4a76-b46f-c742b0bcb014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1.post106\n",
      "None\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"scripts\")\n",
    "from functools import lru_cache\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "# Check if PyTorch is installed\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "print(torch.version.cuda)  # Should match 12.6 or similar\n",
    "print(torch.backends.cudnn.enabled)  # Sho\n",
    "from torch_geometric.data import Data\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import networkx as nx\n",
    "import scripts\n",
    "from scripts import *\n",
    "import torchmetrics\n",
    "from torch import nn\n",
    "import optuna\n",
    "import models\n",
    "from optuna.integration import TensorBoardCallback\n",
    "from model_GNN import ModularPathwayConv, ModularGNN\n",
    "torch.set_printoptions(threshold=torch.inf)\n",
    "from model_ResNet import CombinedModel, ResNet, DrugMLP  \n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "print(f\"Memory allocated: {torch.cuda.memory_allocated() / 1e6} MB\")\n",
    "print(f\"Max memory allocated: {torch.cuda.max_memory_allocated() / 1e6} MB\")\n",
    "import uuid\n",
    "import torch.nn.functional as F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3375c36-291a-4d3e-9559-df17fcab9b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=None)\n",
    "def get_data(n_fold=0, fp_radius=2):\n",
    "    \"\"\"Download, process, and prepare data for use in graph-based machine learning models.\"\"\"\n",
    "    import os\n",
    "    import zipfile\n",
    "    import requests\n",
    "    import torch\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import networkx as nx\n",
    "    from torch_geometric.data import Data\n",
    "    import scripts  # Assuming scripts has required functions\n",
    "\n",
    "    def download_if_not_present(url, filepath):\n",
    "        \"\"\"Download a file from a URL if it does not exist locally.\"\"\"\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"File not found at {filepath}. Downloading...\")\n",
    "            response = requests.get(url, stream=True)\n",
    "            os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "            with open(filepath, \"wb\") as file:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    file.write(chunk)\n",
    "            print(\"Download completed.\")\n",
    "        else:\n",
    "            print(f\"File already exists at {filepath}.\")\n",
    "\n",
    "    # Step 1: Download and load RNA-seq data\n",
    "    zip_url = \"https://cog.sanger.ac.uk/cmp/download/rnaseq_all_20220624.zip\"\n",
    "    zip_filepath = \"data/rnaseq.zip\"\n",
    "    rnaseq_filepath = \"data/rnaseq_normcount.csv\"\n",
    "    if not os.path.exists(rnaseq_filepath):\n",
    "        download_if_not_present(zip_url, zip_filepath)\n",
    "        with zipfile.ZipFile(zip_filepath, \"r\") as zipf:\n",
    "            zipf.extractall(\"data/\")\n",
    "    rnaseq = pd.read_csv(rnaseq_filepath, index_col=0)\n",
    "\n",
    "    # Step 2: Load gene network, hierarchies, and driver genes\n",
    "    hierarchies = pd.read_csv(\"data/gene_to_pathway_final_with_hierarchy.csv\")\n",
    "    driver_genes = pd.read_csv(\"data/driver_genes_2.csv\")['gene'].dropna()\n",
    "    gene_network = nx.read_edgelist(\"data/filtered_gene_network.edgelist\", nodetype=str)\n",
    "    ensembl_to_hgnc = dict(zip(hierarchies['Ensembl_ID'], hierarchies['HGNC']))\n",
    "    mapped_gene_network = nx.relabel_nodes(gene_network, ensembl_to_hgnc)\n",
    "\n",
    "    # Step 3: Filter RNA-seq data and identify valid nodes\n",
    "    driver_columns = rnaseq.columns.isin(driver_genes)\n",
    "    filtered_rna = rnaseq.loc[:, driver_columns]\n",
    "    valid_nodes = set(filtered_rna.columns)  # Get valid nodes after filtering RNA-seq columns\n",
    "\n",
    "    # Step 4: Create edge tensors for the graph\n",
    "    edges_df = pd.DataFrame(\n",
    "        list(mapped_gene_network.edges(data=\"weight\")),\n",
    "        columns=[\"source\", \"target\", \"weight\"]\n",
    "    )\n",
    "    edges_df[\"weight\"] = edges_df[\"weight\"].fillna(1.0).astype(float)\n",
    "    filtered_edges = edges_df[\n",
    "        (edges_df[\"source\"].isin(valid_nodes)) & (edges_df[\"target\"].isin(valid_nodes))\n",
    "    ]\n",
    "    node_to_idx = {node: idx for idx, node in enumerate(valid_nodes)}\n",
    "    filtered_edges[\"source_idx\"] = filtered_edges[\"source\"].map(node_to_idx)\n",
    "    filtered_edges[\"target_idx\"] = filtered_edges[\"target\"].map(node_to_idx)\n",
    "    edge_index = torch.tensor(filtered_edges[[\"source_idx\", \"target_idx\"]].values.T, dtype=torch.long)\n",
    "    edge_attr = torch.tensor(filtered_edges[\"weight\"].values, dtype=torch.float32)\n",
    "\n",
    "    # Step 5: Process the hierarchy to create pathway groups\n",
    "    filtered_hierarchy = hierarchies[hierarchies[\"HGNC\"].isin(valid_nodes)]\n",
    "    pathway_dict = {\n",
    "        gene: pathway.split(':', 1)[1].split('[', 1)[0].strip() if isinstance(pathway, str) and ':' in pathway else None\n",
    "        for gene, pathway in zip(filtered_hierarchy['HGNC'], filtered_hierarchy['Level_1'])\n",
    "    }\n",
    "    grouped_pathway_dict = {}\n",
    "    for gene, pathway in pathway_dict.items():\n",
    "        if pathway:\n",
    "            grouped_pathway_dict.setdefault(pathway, []).append(gene)\n",
    "    pathway_groups = {\n",
    "        pathway: [node_to_idx[gene] for gene in genes if gene in node_to_idx]\n",
    "        for pathway, genes in grouped_pathway_dict.items()\n",
    "    }\n",
    "    # Convert to padded tensor\n",
    "    pathway_tensors = pad_sequence(\n",
    "        [torch.tensor(indices, dtype=torch.long) for indices in pathway_groups.values()], \n",
    "        batch_first=True, \n",
    "        padding_value=-1  # Use -1 as padding\n",
    "    )\n",
    "\n",
    "    # Step 6: Create cell-line graphs\n",
    "    tensor_exp = torch.tensor(filtered_rna.to_numpy())\n",
    "    cell_dict = {cell: tensor_exp[i] for i, cell in enumerate(filtered_rna.index.to_numpy())}\n",
    "    graph_data_list = {}\n",
    "    for cell, x in cell_dict.items():\n",
    "        if x.ndim == 2 and x.shape[0] == 1:\n",
    "            x = x.T\n",
    "        elif x.ndim == 1:\n",
    "            x = x.unsqueeze(1)\n",
    "        graph_data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "        graph_data.y = None\n",
    "        graph_data.cell_line = cell\n",
    "        graph_data_list[cell] = graph_data\n",
    "\n",
    "    # Step 7: Load drug data\n",
    "    smile_dict = pd.read_csv(\"data/smiles.csv\", index_col=0)\n",
    "    fp = scripts.FingerprintFeaturizer(R=fp_radius)\n",
    "    drug_dict = fp(smile_dict.iloc[:, 1], smile_dict.iloc[:, 0])\n",
    "\n",
    "    # Step 8: Load IC50 data and filter for valid cell lines and drugs\n",
    "    data = pd.read_csv(\"data/GDSC1.csv\", index_col=0)\n",
    "    data = data.query(\"SANGER_MODEL_ID in @cell_dict.keys() & DRUG_ID in @drug_dict.keys()\")\n",
    "\n",
    "    # Step 9: Split the data into folds for cross-validation\n",
    "    unique_cell_lines = data[\"SANGER_MODEL_ID\"].unique()\n",
    "    np.random.seed(420)\n",
    "    np.random.shuffle(unique_cell_lines)\n",
    "    folds = np.array_split(unique_cell_lines, 10)\n",
    "    train_idxs = list(range(10))\n",
    "    train_idxs.remove(n_fold)\n",
    "    validation_idx = np.random.choice(train_idxs)\n",
    "    train_idxs.remove(validation_idx)\n",
    "    train_lines = np.concatenate([folds[idx] for idx in train_idxs])\n",
    "    validation_lines = folds[validation_idx]\n",
    "    test_lines = folds[n_fold]\n",
    "\n",
    "    train_data = data.query(\"SANGER_MODEL_ID in @train_lines\")\n",
    "    validation_data = data.query(\"SANGER_MODEL_ID in @validation_lines\")\n",
    "    test_data = data.query(\"SANGER_MODEL_ID in @test_lines\")\n",
    "\n",
    "    # Step 10: Build the datasets for training, validation, and testing\n",
    "    train_dataset = scripts.OmicsDataset(graph_data_list, drug_dict, train_data)\n",
    "    validation_dataset = scripts.OmicsDataset(graph_data_list, drug_dict, validation_data)\n",
    "    test_dataset = scripts.OmicsDataset(graph_data_list, drug_dict, test_data)\n",
    "\n",
    "    return train_dataset, validation_dataset, test_dataset, pathway_tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6194c2e-e218-4089-931e-0208470ee7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graphs, val_graphs, test_graphs, pathway_tensors = get_data(n_fold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0c2da6-a1ef-4360-a518-c26c80038c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Create a DataLoader for training graphs\n",
    "batch_size = 2  # Adjust based on memory and dataset size\n",
    "train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8cbbfa-f261-4e11-a8fa-9d342a4105da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway_groups=torch.tensor([\n",
    "    [2, 1, -1],  # Pathway 1 (nodes 0 and 1)\n",
    "    [0, -1, -1]  # Pathway 2 (node 2)\n",
    "], dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff46b11-d884-4eed-a329-79137fa9dc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for the GNN\n",
    "config = {\n",
    "    \"gnn\": {\n",
    "        \"input_dim\": 1,  # Adjust based on your dataset\n",
    "        \"hidden_dim\": 128,\n",
    "        \"output_dim\": 1,  # Adjust based on your dataset\n",
    "        \"pathway_groups\": None,  # Predefined pathway_groups tensor\n",
    "        \"layer_modes\": [False, False, False],  # Specify global or pathway-specific modes\n",
    "        \"pooling_mode\": \"scalar\",  # Pooling mode for final embeddings\n",
    "        \"aggr_modes\": [\"mean\", \"mean\", \"mean\"],  # Aggregation methods per layer\n",
    "        \"num_pathways_per_instance\": 2\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize the model using the config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ModularGNN(\n",
    "    input_dim=config[\"gnn\"][\"input_dim\"],\n",
    "    hidden_dim=config[\"gnn\"][\"hidden_dim\"],\n",
    "    output_dim=config[\"gnn\"][\"output_dim\"],\n",
    "    pathway_groups=config[\"gnn\"][\"pathway_groups\"],\n",
    "    layer_modes=config[\"gnn\"][\"layer_modes\"],\n",
    "    aggr_modes=config[\"gnn\"][\"aggr_modes\"],\n",
    "    pooling_mode=config[\"gnn\"][\"pooling_mode\"],\n",
    "    num_pathways_per_instance=config[\"gnn\"][\"num_pathways_per_instance\"]\n",
    ").to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7729219-7978-495e-85b6-7aaa113be38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} started...\")\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        try:\n",
    "            # Unpack batch components\n",
    "            cell_graph_batch, drug_tensor_batch, target_batch, cell_id_batch, drug_id_batch = batch\n",
    "        except Exception as e:\n",
    "            print(f\"Error unpacking batch {batch_idx}: {e}\")\n",
    "            print(f\"Batch contents: {batch}\")\n",
    "            continue\n",
    "\n",
    "        # Extract node features (x) and other components\n",
    "        cell_graph = cell_graph_batch.to(device)  # PyG Data object for the cell graph\n",
    "        x = cell_graph.x  # Extract node features\n",
    "        edge_index = cell_graph.edge_index  # Extract edge indices\n",
    "        edge_attr = cell_graph.edge_attr if hasattr(cell_graph, \"edge_attr\") else None  # Extract edge attributes\n",
    "        drug_vector = drug_tensor_batch.to(device)  # Tensor for drug features\n",
    "        targets = target_batch.to(device)  # Tensor for target outputs\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            x=x,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_attr,\n",
    "            pathway_tensor=config[\"gnn\"][\"pathway_groups\"],  # Pathway tensor\n",
    "            batch=cell_graph.batch  # Batch information for pooling\n",
    "        )\n",
    "        print(f\"output shape:{outputs.shape}\")\n",
    "        # Loss computation\n",
    "        loss = F.mse_loss(outputs.squeeze(), targets.squeeze())  # Example: regression loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Feedback for each batch\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Batch {batch_idx + 1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Feedback after each epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} completed. Average Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6550f3-eb95-4bf8-b081-242750829244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define node features and edge index for two graphs\n",
    "x1 = torch.tensor([[1.0], [1.0], [1.0]])  # Node features for graph 1\n",
    "edge_index1 = torch.tensor([[ 1, 2],  # Source nodes\n",
    "                            [0, 0]])  # Target nodes\n",
    "edge_attr1 = torch.tensor([ 1.0, 1.0])  # Edge attributes for graph 1\n",
    "\n",
    "x2 = torch.tensor([[5.0], [2.0], [5.0]])  # Node features for graph 2\n",
    "edge_index2 = torch.tensor([[ 1, 2],  # Source nodes\n",
    "                            [ 0, 1]])  # Target nodes\n",
    "edge_attr2 = torch.tensor([ 2.0, 1.0])  # Edge attributes for graph 2\n",
    "\n",
    "# Define pathways\n",
    "# Pathway tensor for Graph 1\n",
    "pathway_tensor1 = torch.tensor([\n",
    "    [2, 1, -1],  # Pathway 1 (nodes 0 and 1)\n",
    "    [0, -1, -1]  # Pathway 2 (node 2)\n",
    "], dtype=torch.long)\n",
    "\n",
    "# Pathway tensor for Graph 2\n",
    "pathway_tensor2 = torch.tensor([\n",
    "    [0, 2, -1],  # Pathway 1 (nodes 0 and 2)\n",
    "    [1, -1, -1]  # Pathway 2 (node 1)\n",
    "], dtype=torch.long)\n",
    "\n",
    "# Define node features and edge index for two graphs\n",
    "x3 = torch.tensor([[1.0], [2.0], [2.0]])  # Node features for graph 1\n",
    "edge_index3 = torch.tensor([[ 1, 2],  # Source nodes\n",
    "                            [0, 0]])  # Target nodes\n",
    "edge_attr3 = torch.tensor([ 1.0, 2.0])  # Edge attributes for graph 1\n",
    "\n",
    "x4 = torch.tensor([[5.0], [2.0], [5.0]])  # Node features for graph 2\n",
    "edge_index4 = torch.tensor([[ 1, 2],  # Source nodes\n",
    "                            [ 0, 1]])  # Target nodes\n",
    "edge_attr4 = torch.tensor([ 2.0, 1.0])  # Edge attributes for graph 2\n",
    "\n",
    "# Define pathways\n",
    "# Pathway tensor for Graph 1\n",
    "pathway_tensor3 = torch.tensor([\n",
    "    [2, 1, -1],  # Pathway 1 (nodes 0 and 1)\n",
    "    [0, -1, -1]  # Pathway 2 (node 2)\n",
    "], dtype=torch.long)\n",
    "\n",
    "# Pathway tensor for Graph 2\n",
    "pathway_tensor4 = torch.tensor([\n",
    "    [0, 2, -1],  # Pathway 1 (nodes 0 and 2)\n",
    "    [1, -1, -1]  # Pathway 2 (node 1)\n",
    "], dtype=torch.long)\n",
    "\n",
    "# Create Data objects for each graph\n",
    "data1 = Data(x=x1, edge_index=edge_index1, edge_attr=edge_attr1,pathway_tensor = pathway_tensor1)\n",
    "data2 = Data(x=x2, edge_index=edge_index2, edge_attr=edge_attr2,pathway_tensor = pathway_tensor1)\n",
    "data3 = Data(x=x3, edge_index=edge_index3, edge_attr=edge_attr3,pathway_tensor = pathway_tensor1)\n",
    "data4 = Data(x=x4, edge_index=edge_index4, edge_attr=edge_attr4,pathway_tensor = pathway_tensor1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Batch the data\n",
    "batch = Batch.from_data_list([data1, data2,data3,data4])\n",
    "print(batch.pathway_tensor)\n",
    "\n",
    "\n",
    "# Visualize the graphs\n",
    "def visualize_graph(data, title):\n",
    "    G = to_networkx(data, edge_attrs=[\"edge_attr\"])\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G, pos, with_labels=True, node_color='lightblue', node_size=500)\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels={(u, v): f'{d[\"edge_attr\"]}' for u, v, d in G.edges(data=True)})\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "visualize_graph(data1, \"Graph 1\")\n",
    "visualize_graph(data2, \"Graph 2\")\n",
    "\n",
    "## Check batch\n",
    "#print(f\"Batch node features:\\n{batch.x}\")\n",
    "#print(f\"Batch edge index:\\n{batch.edge_index}\")\n",
    "#print(f\"Batch edge attributes:\\n{batch.edge_attr}\")\n",
    "#print(f\"Batch pathways:\\n{batch.pathway_tensor}\")\n",
    "#print(f\"Batch assignment:\\n{batch.batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41881a3c-66d1-4f36-b2cf-872cf87d84d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract components from the batch\n",
    "x = batch.x\n",
    "edge_index = batch.edge_index\n",
    "edge_attr = batch.edge_attr\n",
    "pathway_tensor = batch.pathway_tensor  # Pathway tensor\n",
    "batch_assignment = batch.batch  # Batch assignment vector\n",
    "\n",
    "# Forward pass through the model\n",
    "outputs = model(\n",
    "    x=x,\n",
    "    edge_index=edge_index,\n",
    "    edge_attr=edge_attr,\n",
    "    pathway_tensor=None,\n",
    "    batch=batch_assignment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1237f444-6ede-49a0-a25f-ab97385062a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b82807-0996-4f0c-8103-187137673432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f9507e-b1fb-4c26-849b-549e4202fafb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN2",
   "language": "python",
   "name": "gnn2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
