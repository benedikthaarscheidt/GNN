{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "327c5070-eab2-4bad-baab-9458ab879c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1.post106\n",
      "None\n",
      "True\n",
      "Memory allocated: 0.0 MB\n",
      "Max memory allocated: 0.0 MB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"scripts\")\n",
    "from functools import lru_cache\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch\n",
    "\n",
    "# Check if PyTorch is installed\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "print(torch.version.cuda)  # Should match 12.6 or similar\n",
    "print(torch.backends.cudnn.enabled)  # Sho\n",
    "from torch_geometric.data import Data\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import networkx as nx\n",
    "import scripts\n",
    "from scripts import *\n",
    "import torchmetrics\n",
    "from torch import nn\n",
    "import optuna\n",
    "import models\n",
    "from optuna.integration import TensorBoardCallback\n",
    "from model_GNN import ModularPathwayConv, ModularGNN\n",
    "torch.set_printoptions(threshold=torch.inf)\n",
    "from model_ResNet import CombinedModel, ResNet, DrugMLP  \n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "print(f\"Memory allocated: {torch.cuda.memory_allocated() / 1e6} MB\")\n",
    "print(f\"Max memory allocated: {torch.cuda.max_memory_allocated() / 1e6} MB\")\n",
    "import uuid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f39fab7-2585-4105-a87b-9b115dfff2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=None)\n",
    "def get_data(n_fold=0, fp_radius=2):\n",
    "    \"\"\"Download, process, and prepare data for use in graph-based machine learning models.\"\"\"\n",
    "    import os\n",
    "    import zipfile\n",
    "    import requests\n",
    "    import torch\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import networkx as nx\n",
    "    from torch_geometric.data import Data\n",
    "    import scripts  # Assuming scripts has required functions\n",
    "\n",
    "    def download_if_not_present(url, filepath):\n",
    "        \"\"\"Download a file from a URL if it does not exist locally.\"\"\"\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"File not found at {filepath}. Downloading...\")\n",
    "            response = requests.get(url, stream=True)\n",
    "            os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "            with open(filepath, \"wb\") as file:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    file.write(chunk)\n",
    "            print(\"Download completed.\")\n",
    "        else:\n",
    "            print(f\"File already exists at {filepath}.\")\n",
    "\n",
    "    # Step 1: Download and load RNA-seq data\n",
    "    zip_url = \"https://cog.sanger.ac.uk/cmp/download/rnaseq_all_20220624.zip\"\n",
    "    zip_filepath = \"data/rnaseq.zip\"\n",
    "    rnaseq_filepath = \"data/rnaseq_normcount.csv\"\n",
    "    if not os.path.exists(rnaseq_filepath):\n",
    "        download_if_not_present(zip_url, zip_filepath)\n",
    "        with zipfile.ZipFile(zip_filepath, \"r\") as zipf:\n",
    "            zipf.extractall(\"data/\")\n",
    "    rnaseq = pd.read_csv(rnaseq_filepath, index_col=0)\n",
    "\n",
    "    # Step 2: Load gene network, hierarchies, and driver genes\n",
    "    hierarchies = pd.read_csv(\"data/gene_to_pathway_final_with_hierarchy.csv\")\n",
    "    driver_genes = pd.read_csv(\"data/driver_genes_2.csv\")['gene'].dropna()\n",
    "    gene_network = nx.read_edgelist(\"data/filtered_gene_network.edgelist\", nodetype=str)\n",
    "    ensembl_to_hgnc = dict(zip(hierarchies['Ensembl_ID'], hierarchies['HGNC']))\n",
    "    mapped_gene_network = nx.relabel_nodes(gene_network, ensembl_to_hgnc)\n",
    "\n",
    "    # Step 3: Filter RNA-seq data and identify valid nodes\n",
    "    driver_columns = rnaseq.columns.isin(driver_genes)\n",
    "    filtered_rna = rnaseq.loc[:, driver_columns]\n",
    "    valid_nodes = set(filtered_rna.columns)  # Get valid nodes after filtering RNA-seq columns\n",
    "\n",
    "    # Step 4: Create edge tensors for the graph\n",
    "    edges_df = pd.DataFrame(\n",
    "        list(mapped_gene_network.edges(data=\"weight\")),\n",
    "        columns=[\"source\", \"target\", \"weight\"]\n",
    "    )\n",
    "    edges_df[\"weight\"] = edges_df[\"weight\"].fillna(1.0).astype(float)\n",
    "    filtered_edges = edges_df[\n",
    "        (edges_df[\"source\"].isin(valid_nodes)) & (edges_df[\"target\"].isin(valid_nodes))\n",
    "    ]\n",
    "    node_to_idx = {node: idx for idx, node in enumerate(valid_nodes)}\n",
    "    filtered_edges[\"source_idx\"] = filtered_edges[\"source\"].map(node_to_idx)\n",
    "    filtered_edges[\"target_idx\"] = filtered_edges[\"target\"].map(node_to_idx)\n",
    "    edge_index = torch.tensor(filtered_edges[[\"source_idx\", \"target_idx\"]].values.T, dtype=torch.long)\n",
    "    edge_attr = torch.tensor(filtered_edges[\"weight\"].values, dtype=torch.float32)\n",
    "\n",
    "    # Step 5: Process the hierarchy to create pathway groups\n",
    "    filtered_hierarchy = hierarchies[hierarchies[\"HGNC\"].isin(valid_nodes)]\n",
    "    pathway_dict = {\n",
    "        gene: pathway.split(':', 1)[1].split('[', 1)[0].strip() if isinstance(pathway, str) and ':' in pathway else None\n",
    "        for gene, pathway in zip(filtered_hierarchy['HGNC'], filtered_hierarchy['Level_1'])\n",
    "    }\n",
    "    grouped_pathway_dict = {}\n",
    "    for gene, pathway in pathway_dict.items():\n",
    "        if pathway:\n",
    "            grouped_pathway_dict.setdefault(pathway, []).append(gene)\n",
    "    pathway_groups = {\n",
    "        pathway: [node_to_idx[gene] for gene in genes if gene in node_to_idx]\n",
    "        for pathway, genes in grouped_pathway_dict.items()\n",
    "    }\n",
    "    # Convert to padded tensor\n",
    "    pathway_tensors = pad_sequence(\n",
    "        [torch.tensor(indices, dtype=torch.long) for indices in pathway_groups.values()], \n",
    "        batch_first=True, \n",
    "        padding_value=-1  # Use -1 as padding\n",
    "    )\n",
    "\n",
    "    # Step 6: Create cell-line graphs\n",
    "    tensor_exp = torch.tensor(filtered_rna.to_numpy())\n",
    "    cell_dict = {cell: tensor_exp[i] for i, cell in enumerate(filtered_rna.index.to_numpy())}\n",
    "    graph_data_list = {}\n",
    "    for cell, x in cell_dict.items():\n",
    "        if x.ndim == 2 and x.shape[0] == 1:\n",
    "            x = x.T\n",
    "        elif x.ndim == 1:\n",
    "            x = x.unsqueeze(1)\n",
    "        graph_data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "        graph_data.y = None\n",
    "        graph_data.cell_line = cell\n",
    "        graph_data_list[cell] = graph_data\n",
    "\n",
    "    # Step 7: Load drug data\n",
    "    smile_dict = pd.read_csv(\"data/smiles.csv\", index_col=0)\n",
    "    fp = scripts.FingerprintFeaturizer(R=fp_radius)\n",
    "    drug_dict = fp(smile_dict.iloc[:, 1], smile_dict.iloc[:, 0])\n",
    "\n",
    "    # Step 8: Load IC50 data and filter for valid cell lines and drugs\n",
    "    data = pd.read_csv(\"data/GDSC1.csv\", index_col=0)\n",
    "    data = data.query(\"SANGER_MODEL_ID in @cell_dict.keys() & DRUG_ID in @drug_dict.keys()\")\n",
    "\n",
    "    # Step 9: Split the data into folds for cross-validation\n",
    "    unique_cell_lines = data[\"SANGER_MODEL_ID\"].unique()\n",
    "    np.random.seed(420)\n",
    "    np.random.shuffle(unique_cell_lines)\n",
    "    folds = np.array_split(unique_cell_lines, 10)\n",
    "    train_idxs = list(range(10))\n",
    "    train_idxs.remove(n_fold)\n",
    "    validation_idx = np.random.choice(train_idxs)\n",
    "    train_idxs.remove(validation_idx)\n",
    "    train_lines = np.concatenate([folds[idx] for idx in train_idxs])\n",
    "    validation_lines = folds[validation_idx]\n",
    "    test_lines = folds[n_fold]\n",
    "\n",
    "    train_data = data.query(\"SANGER_MODEL_ID in @train_lines\")\n",
    "    validation_data = data.query(\"SANGER_MODEL_ID in @validation_lines\")\n",
    "    test_data = data.query(\"SANGER_MODEL_ID in @test_lines\")\n",
    "\n",
    "    # Step 10: Build the datasets for training, validation, and testing\n",
    "    train_dataset = scripts.OmicsDataset(graph_data_list, drug_dict, train_data)\n",
    "    validation_dataset = scripts.OmicsDataset(graph_data_list, drug_dict, validation_data)\n",
    "    test_dataset = scripts.OmicsDataset(graph_data_list, drug_dict, test_data)\n",
    "\n",
    "    return train_dataset, validation_dataset, test_dataset, pathway_tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93db7a6f-24d4-48e7-8dc9-9ae4b4d0448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data, pathway_groups=get_data(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea3d075f-7678-439b-9e50-aa9ba42d682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    try:\n",
    "        cell_graphs = [item[0] for item in batch if item[0] is not None]\n",
    "        if len(cell_graphs) == 0:\n",
    "            raise ValueError(\"No graphs to batch in this batch. Batch might be empty or contains None.\")\n",
    "        \n",
    "        drug_vectors = torch.stack([item[1] for item in batch if item[1] is not None])  # Stack drug vectors\n",
    "        targets = torch.stack([item[2] for item in batch if item[2] is not None])  # Stack target values\n",
    "        cell_ids = torch.stack([item[3] for item in batch if item[3] is not None])  # Stack cell IDs\n",
    "        drug_ids = torch.stack([item[4] for item in batch if item[4] is not None])  # Stack drug IDs\n",
    "\n",
    "        # Batch the PyG graphs into a single DataBatch\n",
    "        cell_graph_batch = Batch.from_data_list(cell_graphs)\n",
    "        return cell_graph_batch, drug_vectors, targets, cell_ids, drug_ids\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in custom_collate_fn: {e}\")\n",
    "        print(f\"Batch contents: {batch}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aecbf01f-4c3b-42fb-8be4-a754fb83c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gnn_model = ModularGNN(**config[\"gnn\"])\n",
    "#drug_mlp = DrugMLP(input_dim=config[\"drug\"][\"input_dim\"], embed_dim=config[\"drug\"][\"embed_dim\"])\n",
    "#resnet = ResNet(embed_dim=config[\"drug\"][\"embed_dim\"], hidden_dim=config[\"resnet\"][\"hidden_dim\"], \n",
    "#                n_layers=config[\"resnet\"][\"n_layers\"], dropout=config[\"resnet\"][\"dropout\"])\n",
    "#\n",
    "#combined_model = CombinedModel(gnn=gnn_model, drug_mlp=drug_mlp, resnet=resnet)\n",
    "#\n",
    "#device = torch.device(config[\"env\"][\"device\"])\n",
    "#combined_model.to(device)\n",
    "#print(pathway_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5578d616-6f7b-4936-9516-d526e86f32e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_lazy_layers(model, test_instance, drug_input_size, device='cpu'):\n",
    "    \"\"\"Initializes lazy layers for the model using a real batch instance.\"\"\"\n",
    "    if hasattr(model, 'lazy_initialized') and model.lazy_initialized:\n",
    "        print(\"Lazy layers are already initialized.\")\n",
    "        return  # Skip re-initialization\n",
    "\n",
    "    print(\"Initializing lazy layers...\")\n",
    "\n",
    "    # Extract graph data and prepare a test instance\n",
    "    x = test_instance.x.to(device)  \n",
    "    edge_index = test_instance.edge_index.to(device)  \n",
    "    edge_attr = test_instance.edge_attr.to(device) if hasattr(test_instance, 'edge_attr') else None\n",
    "    pathway_tensor = test_instance.pathway_tensor.to(device) if hasattr(test_instance, 'pathway_tensor') else None\n",
    "    \n",
    "    graph_data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, pathway_tensor=pathway_tensor)\n",
    "    dummy_drug = torch.randn(1, drug_input_size).to(device)  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        model(graph_data, dummy_drug, batch=test_instance.batch.to(device))\n",
    "    \n",
    "    model.lazy_initialized = True  # Track initialization state\n",
    "    print(\"Lazy layers initialized successfully with a real batch instance.\")\n",
    "\n",
    "def train_model_optuna(trial, base_config, train_dataset, validation_dataset):\n",
    "    copy_config = deepcopy(base_config)\n",
    "    device = torch.device(copy_config[\"env\"][\"device\"])\n",
    "\n",
    "    def pruning_callback(epoch, train_r):\n",
    "        trial.report(train_r, step=epoch)\n",
    "        if np.isnan(train_r):\n",
    "            raise optuna.TrialPruned()\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    try:\n",
    "        pathway_count = 44  # Number of pathways\n",
    "        if copy_config[\"gnn\"][\"pooling_mode\"] == 'pathway':\n",
    "            final_gnn_output_dim = pathway_count * copy_config[\"gnn\"][\"output_dim\"]\n",
    "        else:\n",
    "            final_gnn_output_dim = copy_config[\"gnn\"][\"output_dim\"]\n",
    "\n",
    "        # Update DrugMLP to match GNN output\n",
    "        copy_config[\"drug\"].update({\n",
    "            \"input_dim\": 2048,  \n",
    "            \"embed_dim\": final_gnn_output_dim  # Ensure DrugMLP matches GNN\n",
    "        })\n",
    "        # Instantiate the models\n",
    "        gnn_model = ModularGNN(**copy_config[\"gnn\"])  \n",
    "        drug_mlp = DrugMLP(input_dim=copy_config[\"drug\"][\"input_dim\"], embed_dim=copy_config[\"drug\"][\"embed_dim\"])\n",
    "        resnet = ResNet(\n",
    "            embed_dim=copy_config[\"resnet\"][\"embed_dim\"], \n",
    "            hidden_dim=copy_config[\"resnet\"][\"hidden_dim\"], \n",
    "            n_layers=copy_config[\"resnet\"][\"n_layers\"], \n",
    "            dropout=copy_config[\"resnet\"][\"dropout\"]\n",
    "        )\n",
    "\n",
    "        combined_model = CombinedModel(gnn=gnn_model, drug_mlp=drug_mlp, resnet=resnet)\n",
    "\n",
    "        # Create a DataLoader for training\n",
    "        train_loader = DataLoader(train_dataset, batch_size=copy_config[\"optimizer\"][\"batch_size\"], shuffle=True) \n",
    "        test_instance = next(iter(train_loader))[0]  \n",
    "\n",
    "        initialize_lazy_layers(\n",
    "            model=combined_model, \n",
    "            test_instance=test_instance, \n",
    "            drug_input_size=2048, \n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        combined_model.to(device)\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            combined_model = torch.nn.DataParallel(combined_model)\n",
    "\n",
    "        optimizer = torch.optim.Adam(combined_model.parameters(), lr=copy_config[\"optimizer\"][\"learning_rate\"])\n",
    "\n",
    "        for epoch in range(copy_config[\"env\"][\"max_epochs\"]):\n",
    "            combined_model.train()\n",
    "            total_loss = 0\n",
    "\n",
    "            for batch_idx, batch in enumerate(train_loader):\n",
    "                try:\n",
    "                    cell_graph_batch, drug_tensor_batch, target_batch, cell_id_batch, drug_id_batch = batch\n",
    "\n",
    "                    # Move batch to device\n",
    "                    cell_graph = cell_graph_batch.to(device)\n",
    "                    x = cell_graph.x\n",
    "                    edge_index = cell_graph.edge_index\n",
    "                    edge_attr = cell_graph.edge_attr if hasattr(cell_graph, \"edge_attr\") else None\n",
    "                    pathway_tensor = cell_graph.pathway_tensor if hasattr(cell_graph, \"pathway_tensor\") else None\n",
    "                    batch_tensor = cell_graph.batch  # Batch info\n",
    "\n",
    "                    drug_vector = drug_tensor_batch.to(device)  # Drug tensor\n",
    "                    targets = target_batch.to(device)  # True target\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # Forward pass\n",
    "                    outputs = combined_model(\n",
    "                        x=x,\n",
    "                        edge_index=edge_index,\n",
    "                        edge_attr=edge_attr,\n",
    "                        pathway_tensor=pathway_tensor,\n",
    "                        batch=batch_tensor,\n",
    "                        drug_vector=drug_vector\n",
    "                    )\n",
    "\n",
    "                    # Loss computation\n",
    "                    loss = F.mse_loss(outputs, targets)\n",
    "                    loss.backward()\n",
    "\n",
    "                    # Gradient clipping\n",
    "                    torch.nn.utils.clip_grad_norm_(combined_model.parameters(), max_norm=copy_config[\"optimizer\"][\"clip_norm\"])\n",
    "\n",
    "                    optimizer.step()\n",
    "                    total_loss += loss.item()\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Exception during batch processing: {e}\")\n",
    "                    continue\n",
    "\n",
    "            avg_loss = total_loss / len(train_loader)\n",
    "            print(f\"Epoch {epoch + 1}/{copy_config['env']['max_epochs']} completed. Average Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        return avg_loss\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred during training: {e}\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    base_config = deepcopy(config)\n",
    "    R = train_model_optuna(trial, base_config, train_data, val_data)\n",
    "    return R\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"gnn\": {\n",
    "        \"input_dim\": 1,\n",
    "        \"hidden_dim\": 128,\n",
    "        \"output_dim\": 1,\n",
    "        \"pathway_groups\": pathway_tensors,\n",
    "        \"layer_modes\": [True, True, True],\n",
    "        \"pooling_mode\": \"pathway\",\n",
    "        \"aggr_modes\": [\"mean\", \"mean\", \"mean\"],\n",
    "        \"num_pathways_per_instance\": 44\n",
    "    },\n",
    "    \"resnet\": {\n",
    "        \"hidden_dim\": 512,\n",
    "        \"n_layers\": 6,\n",
    "        \"dropout\": 0.1,\n",
    "    },\n",
    "    \"drug\": {\n",
    "        \"input_dim\": 2048,\n",
    "        \"embed_dim\": 128\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"clip_norm\": 1.0,\n",
    "        \"batch_size\": 2,\n",
    "        \"stopping_patience\": 10,\n",
    "    },\n",
    "    \"env\": {\n",
    "        \"device\": \"cuda\" if torch.cuda.is_available() else 'cpu',\n",
    "        \"max_epochs\": 50,\n",
    "        \"search_hyperparameters\": True  \n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "847b1639-b863-4807-9c78-ca81d00455d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:17,403] A new study created in RDB with name: baseline_model_81d6518d\n",
      "/work/haarscheid/.conda/envs/GNN2/lib/python3.12/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ('sum', 'mean', 'max') which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/work/haarscheid/.conda/envs/GNN2/lib/python3.12/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ('mean', 'max', 'sum') which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/work/haarscheid/.conda/envs/GNN2/lib/python3.12/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ('max', 'sum', 'mean') which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/work/haarscheid/.conda/envs/GNN2/lib/python3.12/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ('sum', 'sum', 'sum') which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/work/haarscheid/.conda/envs/GNN2/lib/python3.12/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ('mean', 'mean', 'mean') which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/work/haarscheid/.conda/envs/GNN2/lib/python3.12/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ('max', 'max', 'max') which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/work/haarscheid/.conda/envs/GNN2/lib/python3.12/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['sum', 'mean', 'max'] which is of type list.\n",
      "  warnings.warn(message)\n",
      "/work/haarscheid/.conda/envs/GNN2/lib/python3.12/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['mean', 'max', 'sum'] which is of type list.\n",
      "  warnings.warn(message)\n",
      "/work/haarscheid/.conda/envs/GNN2/lib/python3.12/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['max', 'sum', 'mean'] which is of type list.\n",
      "  warnings.warn(message)\n",
      "/work/haarscheid/.conda/envs/GNN2/lib/python3.12/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['sum', 'sum', 'sum'] which is of type list.\n",
      "  warnings.warn(message)\n",
      "/work/haarscheid/.conda/envs/GNN2/lib/python3.12/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['mean', 'mean', 'mean'] which is of type list.\n",
      "  warnings.warn(message)\n",
      "/work/haarscheid/.conda/envs/GNN2/lib/python3.12/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['max', 'max', 'max'] which is of type list.\n",
      "  warnings.warn(message)\n",
      "[I 2024-12-13 18:38:17,718] Trial 0 finished with value: 0.0 and parameters: {'hidden_dim': 374, 'output_dim': 123, 'pooling_mode': 'pathway', 'aggr_modes': ['mean', 'max', 'sum'], 'hidden_dim_resnet': 406, 'n_layers': 2, 'dropout': 0.032274042083852594, 'learning_rate': 1.2816020703040994e-05, 'clip_norm': 2.0437080747317236, 'batch_size': 5}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('mean', 'max', 'sum')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:17,943] Trial 1 finished with value: 0.0 and parameters: {'hidden_dim': 231, 'output_dim': 120, 'pooling_mode': 'none', 'aggr_modes': ['max', 'sum', 'mean'], 'hidden_dim_resnet': 273, 'n_layers': 4, 'dropout': 0.3317268084353495, 'learning_rate': 0.0010782737619025333, 'clip_norm': 17.897289906941182, 'batch_size': 6}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('max', 'sum', 'mean')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:18,175] Trial 2 finished with value: 0.0 and parameters: {'hidden_dim': 220, 'output_dim': 162, 'pooling_mode': 'pathway', 'aggr_modes': ['sum', 'mean', 'max'], 'hidden_dim_resnet': 224, 'n_layers': 1, 'dropout': 0.04638900655253736, 'learning_rate': 3.940482062806518e-05, 'clip_norm': 5.75636495832537, 'batch_size': 4}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('sum', 'mean', 'max')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:18,454] Trial 3 finished with value: 0.0 and parameters: {'hidden_dim': 207, 'output_dim': 172, 'pooling_mode': 'scalar', 'aggr_modes': ['max', 'sum', 'mean'], 'hidden_dim_resnet': 68, 'n_layers': 5, 'dropout': 0.48040599522391586, 'learning_rate': 0.06345155515060766, 'clip_norm': 15.845269400809869, 'batch_size': 5}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('max', 'sum', 'mean')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:18,724] Trial 4 finished with value: 0.0 and parameters: {'hidden_dim': 139, 'output_dim': 252, 'pooling_mode': 'none', 'aggr_modes': ['sum', 'mean', 'max'], 'hidden_dim_resnet': 253, 'n_layers': 6, 'dropout': 0.3831253591918398, 'learning_rate': 2.082125188206426e-06, 'clip_norm': 4.412786443323326, 'batch_size': 5}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('sum', 'mean', 'max')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:18,981] Trial 5 finished with value: 0.0 and parameters: {'hidden_dim': 506, 'output_dim': 119, 'pooling_mode': 'scalar', 'aggr_modes': ['sum', 'mean', 'max'], 'hidden_dim_resnet': 101, 'n_layers': 4, 'dropout': 0.005461197942341678, 'learning_rate': 0.003233996313992134, 'clip_norm': 9.946148216541083, 'batch_size': 3}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('sum', 'mean', 'max')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:19,252] Trial 6 finished with value: 0.0 and parameters: {'hidden_dim': 281, 'output_dim': 157, 'pooling_mode': 'none', 'aggr_modes': ['mean', 'mean', 'mean'], 'hidden_dim_resnet': 233, 'n_layers': 3, 'dropout': 0.08734779259053155, 'learning_rate': 4.112653380290154e-05, 'clip_norm': 7.082237287436878, 'batch_size': 2}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('mean', 'mean', 'mean')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:19,534] Trial 7 finished with value: 0.0 and parameters: {'hidden_dim': 191, 'output_dim': 117, 'pooling_mode': 'scalar', 'aggr_modes': ['sum', 'mean', 'max'], 'hidden_dim_resnet': 423, 'n_layers': 1, 'dropout': 0.05700294821287488, 'learning_rate': 0.048065187031486406, 'clip_norm': 2.8672026163421527, 'batch_size': 8}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('sum', 'mean', 'max')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:19,838] Trial 8 finished with value: 0.0 and parameters: {'hidden_dim': 162, 'output_dim': 193, 'pooling_mode': 'none', 'aggr_modes': ['mean', 'mean', 'mean'], 'hidden_dim_resnet': 313, 'n_layers': 4, 'dropout': 0.2150735361089237, 'learning_rate': 2.3950947115169918e-05, 'clip_norm': 15.535172220514044, 'batch_size': 4}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('mean', 'mean', 'mean')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:20,124] Trial 9 finished with value: 0.0 and parameters: {'hidden_dim': 172, 'output_dim': 144, 'pooling_mode': 'scalar', 'aggr_modes': ['mean', 'mean', 'mean'], 'hidden_dim_resnet': 490, 'n_layers': 2, 'dropout': 0.15669704071535834, 'learning_rate': 1.5488957669079778e-05, 'clip_norm': 16.867233677773427, 'batch_size': 6}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('mean', 'mean', 'mean')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:20,380] Trial 10 finished with value: 0.0 and parameters: {'hidden_dim': 417, 'output_dim': 68, 'pooling_mode': 'pathway', 'aggr_modes': ['mean', 'max', 'sum'], 'hidden_dim_resnet': 386, 'n_layers': 2, 'dropout': 0.1818368583632016, 'learning_rate': 1.1266612002844648e-06, 'clip_norm': 0.42179486232997077, 'batch_size': 8}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('mean', 'max', 'sum')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:20,669] Trial 11 finished with value: 0.0 and parameters: {'hidden_dim': 353, 'output_dim': 77, 'pooling_mode': 'pathway', 'aggr_modes': ['mean', 'max', 'sum'], 'hidden_dim_resnet': 343, 'n_layers': 3, 'dropout': 0.3234466085290543, 'learning_rate': 0.0005913954717308875, 'clip_norm': 19.71975243960814, 'batch_size': 6}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('mean', 'max', 'sum')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:20,972] Trial 12 finished with value: 0.0 and parameters: {'hidden_dim': 332, 'output_dim': 113, 'pooling_mode': 'none', 'aggr_modes': ['max', 'max', 'max'], 'hidden_dim_resnet': 156, 'n_layers': 5, 'dropout': 0.28843800545526915, 'learning_rate': 0.0006943946525860286, 'clip_norm': 11.829093092535436, 'batch_size': 7}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('max', 'max', 'max')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:21,334] Trial 13 finished with value: 0.0 and parameters: {'hidden_dim': 91, 'output_dim': 92, 'pooling_mode': 'pathway', 'aggr_modes': ['sum', 'sum', 'sum'], 'hidden_dim_resnet': 502, 'n_layers': 2, 'dropout': 0.3980907435089409, 'learning_rate': 0.004796162362888737, 'clip_norm': 10.792748730061685, 'batch_size': 1}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('sum', 'sum', 'sum')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:21,704] Trial 14 finished with value: 0.0 and parameters: {'hidden_dim': 420, 'output_dim': 208, 'pooling_mode': 'none', 'aggr_modes': ['max', 'sum', 'mean'], 'hidden_dim_resnet': 430, 'n_layers': 3, 'dropout': 0.3466370463776269, 'learning_rate': 0.00016106876992112503, 'clip_norm': 0.3111605184165531, 'batch_size': 6}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('max', 'sum', 'mean')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:22,056] Trial 15 finished with value: 0.0 and parameters: {'hidden_dim': 270, 'output_dim': 135, 'pooling_mode': 'pathway', 'aggr_modes': ['max', 'sum', 'mean'], 'hidden_dim_resnet': 351, 'n_layers': 5, 'dropout': 0.2514377150881901, 'learning_rate': 6.1975512418417875e-06, 'clip_norm': 8.318317862987952, 'batch_size': 7}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('max', 'sum', 'mean')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:22,403] Trial 16 finished with value: 0.0 and parameters: {'hidden_dim': 378, 'output_dim': 99, 'pooling_mode': 'pathway', 'aggr_modes': ['mean', 'max', 'sum'], 'hidden_dim_resnet': 284, 'n_layers': 4, 'dropout': 0.12853474019602937, 'learning_rate': 0.00014071420735501514, 'clip_norm': 13.896407282651893, 'batch_size': 3}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('mean', 'max', 'sum')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:22,759] Trial 17 finished with value: 0.0 and parameters: {'hidden_dim': 464, 'output_dim': 134, 'pooling_mode': 'none', 'aggr_modes': ['max', 'max', 'max'], 'hidden_dim_resnet': 170, 'n_layers': 2, 'dropout': 0.46282996409781446, 'learning_rate': 0.0043042548894191455, 'clip_norm': 19.41889375280814, 'batch_size': 5}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('max', 'max', 'max')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:23,056] Trial 18 finished with value: 0.0 and parameters: {'hidden_dim': 310, 'output_dim': 180, 'pooling_mode': 'none', 'aggr_modes': ['sum', 'sum', 'sum'], 'hidden_dim_resnet': 428, 'n_layers': 6, 'dropout': 0.25804602279820693, 'learning_rate': 0.015175860194938176, 'clip_norm': 12.465792946762315, 'batch_size': 7}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('sum', 'sum', 'sum')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:23,397] Trial 19 finished with value: 0.0 and parameters: {'hidden_dim': 255, 'output_dim': 224, 'pooling_mode': 'pathway', 'aggr_modes': ['max', 'sum', 'mean'], 'hidden_dim_resnet': 369, 'n_layers': 1, 'dropout': 0.41429781217794903, 'learning_rate': 0.001303530928097994, 'clip_norm': 3.6754256679562323, 'batch_size': 3}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('max', 'sum', 'mean')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:23,724] Trial 20 finished with value: 0.0 and parameters: {'hidden_dim': 71, 'output_dim': 94, 'pooling_mode': 'none', 'aggr_modes': ['mean', 'max', 'sum'], 'hidden_dim_resnet': 290, 'n_layers': 3, 'dropout': 0.31249693137414175, 'learning_rate': 0.00017128731179436675, 'clip_norm': 9.589308295769857, 'batch_size': 4}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('mean', 'max', 'sum')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:24,078] Trial 21 finished with value: 0.0 and parameters: {'hidden_dim': 230, 'output_dim': 152, 'pooling_mode': 'pathway', 'aggr_modes': ['sum', 'mean', 'max'], 'hidden_dim_resnet': 205, 'n_layers': 1, 'dropout': 0.00858763288137247, 'learning_rate': 6.500988815382135e-05, 'clip_norm': 5.942957894879722, 'batch_size': 4}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('sum', 'mean', 'max')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:24,422] Trial 22 finished with value: 0.0 and parameters: {'hidden_dim': 242, 'output_dim': 166, 'pooling_mode': 'pathway', 'aggr_modes': ['max', 'sum', 'mean'], 'hidden_dim_resnet': 199, 'n_layers': 1, 'dropout': 0.07473322417258732, 'learning_rate': 5.336331004763619e-06, 'clip_norm': 2.335738771021844, 'batch_size': 5}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('max', 'sum', 'mean')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:24,762] Trial 23 finished with value: 0.0 and parameters: {'hidden_dim': 127, 'output_dim': 132, 'pooling_mode': 'pathway', 'aggr_modes': ['mean', 'max', 'sum'], 'hidden_dim_resnet': 271, 'n_layers': 2, 'dropout': 0.10047748855651095, 'learning_rate': 8.086927811183368e-06, 'clip_norm': 5.473513522327822, 'batch_size': 6}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('mean', 'max', 'sum')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:25,085] Trial 24 finished with value: 0.0 and parameters: {'hidden_dim': 304, 'output_dim': 185, 'pooling_mode': 'pathway', 'aggr_modes': ['sum', 'mean', 'max'], 'hidden_dim_resnet': 322, 'n_layers': 1, 'dropout': 0.04290242555635258, 'learning_rate': 7.058809629808089e-05, 'clip_norm': 2.0470299382361006, 'batch_size': 4}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('sum', 'mean', 'max')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:25,404] Trial 25 finished with value: 0.0 and parameters: {'hidden_dim': 382, 'output_dim': 110, 'pooling_mode': 'pathway', 'aggr_modes': ['max', 'max', 'max'], 'hidden_dim_resnet': 134, 'n_layers': 4, 'dropout': 0.19790109784517135, 'learning_rate': 0.00036665729472987147, 'clip_norm': 7.651729654583187, 'batch_size': 2}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('max', 'max', 'max')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:25,749] Trial 26 finished with value: 0.0 and parameters: {'hidden_dim': 218, 'output_dim': 146, 'pooling_mode': 'pathway', 'aggr_modes': ['sum', 'sum', 'sum'], 'hidden_dim_resnet': 220, 'n_layers': 2, 'dropout': 0.15550735408626568, 'learning_rate': 1.919623843276118e-05, 'clip_norm': 5.638444305496632, 'batch_size': 5}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('sum', 'sum', 'sum')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:26,076] Trial 27 finished with value: 0.0 and parameters: {'hidden_dim': 334, 'output_dim': 127, 'pooling_mode': 'pathway', 'aggr_modes': ['mean', 'max', 'sum'], 'hidden_dim_resnet': 464, 'n_layers': 3, 'dropout': 0.11671092124076803, 'learning_rate': 0.0015794662289311055, 'clip_norm': 1.5094426843944386, 'batch_size': 6}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('mean', 'max', 'sum')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:26,436] Trial 28 finished with value: 0.0 and parameters: {'hidden_dim': 430, 'output_dim': 202, 'pooling_mode': 'none', 'aggr_modes': ['sum', 'mean', 'max'], 'hidden_dim_resnet': 246, 'n_layers': 1, 'dropout': 0.027646922032599275, 'learning_rate': 3.281540515681855e-06, 'clip_norm': 4.212115759466326, 'batch_size': 7}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('sum', 'mean', 'max')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:26,767] Trial 29 finished with value: 0.0 and parameters: {'hidden_dim': 204, 'output_dim': 169, 'pooling_mode': 'scalar', 'aggr_modes': ['max', 'sum', 'mean'], 'hidden_dim_resnet': 384, 'n_layers': 5, 'dropout': 0.4780920626129515, 'learning_rate': 0.013000326122990853, 'clip_norm': 17.37822098437342, 'batch_size': 5}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('max', 'sum', 'mean')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:27,112] Trial 30 finished with value: 0.0 and parameters: {'hidden_dim': 262, 'output_dim': 101, 'pooling_mode': 'scalar', 'aggr_modes': ['max', 'sum', 'mean'], 'hidden_dim_resnet': 179, 'n_layers': 4, 'dropout': 0.358927927326715, 'learning_rate': 1.1519163581424118e-05, 'clip_norm': 8.703036731935951, 'batch_size': 3}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('max', 'sum', 'mean')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:27,429] Trial 31 finished with value: 0.0 and parameters: {'hidden_dim': 129, 'output_dim': 251, 'pooling_mode': 'scalar', 'aggr_modes': ['max', 'sum', 'mean'], 'hidden_dim_resnet': 89, 'n_layers': 6, 'dropout': 0.43698317160432304, 'learning_rate': 0.015055223404073491, 'clip_norm': 18.280474220994666, 'batch_size': 5}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('max', 'sum', 'mean')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:27,742] Trial 32 finished with value: 0.0 and parameters: {'hidden_dim': 165, 'output_dim': 172, 'pooling_mode': 'scalar', 'aggr_modes': ['max', 'sum', 'mean'], 'hidden_dim_resnet': 133, 'n_layers': 5, 'dropout': 0.499487222387887, 'learning_rate': 0.08846884698404181, 'clip_norm': 15.90411834313348, 'batch_size': 4}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('max', 'sum', 'mean')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:28,055] Trial 33 finished with value: 0.0 and parameters: {'hidden_dim': 197, 'output_dim': 158, 'pooling_mode': 'scalar', 'aggr_modes': ['sum', 'mean', 'max'], 'hidden_dim_resnet': 113, 'n_layers': 5, 'dropout': 0.3640798502013539, 'learning_rate': 4.921388608614888e-05, 'clip_norm': 14.771941713052373, 'batch_size': 5}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('sum', 'mean', 'max')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:28,373] Trial 34 finished with value: 0.0 and parameters: {'hidden_dim': 510, 'output_dim': 142, 'pooling_mode': 'scalar', 'aggr_modes': ['sum', 'mean', 'max'], 'hidden_dim_resnet': 74, 'n_layers': 6, 'dropout': 0.4311031036357801, 'learning_rate': 0.00755578673455639, 'clip_norm': 13.35317869568825, 'batch_size': 6}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('sum', 'mean', 'max')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:28,731] Trial 35 finished with value: 0.0 and parameters: {'hidden_dim': 289, 'output_dim': 124, 'pooling_mode': 'none', 'aggr_modes': ['mean', 'mean', 'mean'], 'hidden_dim_resnet': 256, 'n_layers': 4, 'dropout': 0.06762235514618119, 'learning_rate': 3.062286148896844e-05, 'clip_norm': 18.54401518139306, 'batch_size': 3}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('mean', 'mean', 'mean')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:29,135] Trial 36 finished with value: 0.0 and parameters: {'hidden_dim': 232, 'output_dim': 219, 'pooling_mode': 'scalar', 'aggr_modes': ['max', 'sum', 'mean'], 'hidden_dim_resnet': 319, 'n_layers': 4, 'dropout': 0.22880678477614796, 'learning_rate': 0.02826992036644315, 'clip_norm': 6.863134419111767, 'batch_size': 4}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('max', 'sum', 'mean')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:29,477] Trial 37 finished with value: 0.0 and parameters: {'hidden_dim': 194, 'output_dim': 181, 'pooling_mode': 'none', 'aggr_modes': ['sum', 'mean', 'max'], 'hidden_dim_resnet': 233, 'n_layers': 5, 'dropout': 0.2774789761075311, 'learning_rate': 2.2931037764925398e-06, 'clip_norm': 16.569730541488646, 'batch_size': 6}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('sum', 'mean', 'max')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:29,826] Trial 38 finished with value: 0.0 and parameters: {'hidden_dim': 167, 'output_dim': 158, 'pooling_mode': 'scalar', 'aggr_modes': ['mean', 'mean', 'mean'], 'hidden_dim_resnet': 405, 'n_layers': 3, 'dropout': 0.00988068385014626, 'learning_rate': 0.002052451062745524, 'clip_norm': 3.3321405469090646, 'batch_size': 2}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('mean', 'mean', 'mean')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-13 18:38:30,148] Trial 39 finished with value: 0.0 and parameters: {'hidden_dim': 149, 'output_dim': 83, 'pooling_mode': 'pathway', 'aggr_modes': ['mean', 'max', 'sum'], 'hidden_dim_resnet': 454, 'n_layers': 1, 'dropout': 0.16434885947345773, 'learning_rate': 0.00013130409533804836, 'clip_norm': 17.611048377991743, 'batch_size': 4}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aggregation mode: ('mean', 'max', 'sum')\n",
      "Exception occurred during training: ModularGNN.__init__() missing 1 required positional argument: 'num_pathways_per_instance'\n",
      "Best Config:  {'hidden_dim': 374, 'output_dim': 123, 'pooling_mode': 'pathway', 'aggr_modes': ['mean', 'max', 'sum'], 'hidden_dim_resnet': 406, 'n_layers': 2, 'dropout': 0.032274042083852594, 'learning_rate': 1.2816020703040994e-05, 'clip_norm': 2.0437080747317236, 'batch_size': 5}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train_model() got an unexpected keyword argument 'use_momentum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 39\u001b[0m\n\u001b[1;32m     27\u001b[0m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_dim_resnet\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     31\u001b[0m })\n\u001b[1;32m     33\u001b[0m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     37\u001b[0m })\n\u001b[0;32m---> 39\u001b[0m _, model \u001b[38;5;241m=\u001b[39m train_model(config, train_data, val_data, use_momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     41\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     42\u001b[0m metrics \u001b[38;5;241m=\u001b[39m torchmetrics\u001b[38;5;241m.\u001b[39mMetricTracker(torchmetrics\u001b[38;5;241m.\u001b[39mMetricCollection({\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR_cellwise_residuals\u001b[39m\u001b[38;5;124m\"\u001b[39m: torchmetrics\u001b[38;5;241m.\u001b[39mPearsonCorrCoef(num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR_cellwise\u001b[39m\u001b[38;5;124m\"\u001b[39m: torchmetrics\u001b[38;5;241m.\u001b[39mPearsonCorrCoef(num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m: torchmetrics\u001b[38;5;241m.\u001b[39mMeanSquaredError()\n\u001b[1;32m     46\u001b[0m }))\n",
      "\u001b[0;31mTypeError\u001b[0m: train_model() got an unexpected keyword argument 'use_momentum'"
     ]
    }
   ],
   "source": [
    "if config[\"env\"][\"search_hyperparameters\"]:\n",
    "    study_name = \"baseline_model\"\n",
    "    storage_name = f\"sqlite:///studies/{study_name}.db\"\n",
    "    unique_study_name = f\"baseline_model_{str(uuid.uuid4())[:8]}\"  # Random suffix for uniqueness\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        study_name=unique_study_name,\n",
    "        storage=storage_name,\n",
    "        direction='maximize',\n",
    "        load_if_exists=False,  # No issue since the study name is always unique\n",
    "        pruner=optuna.pruners.MedianPruner(n_startup_trials=30, n_warmup_steps=5, interval_steps=5)\n",
    "    )\n",
    "\n",
    "\n",
    "    study.optimize(objective, n_trials=40)\n",
    "\n",
    "    best_config = study.best_params\n",
    "    print(\"Best Config: \", best_config)\n",
    "\n",
    "    config[\"gnn\"].update({\n",
    "        \"hidden_dim\": best_config[\"hidden_dim\"],\n",
    "        \"output_dim\": best_config[\"output_dim\"],\n",
    "        \"pooling_mode\": best_config[\"pooling_mode\"],\n",
    "        \"aggr_modes\": best_config[\"aggr_modes\"]\n",
    "        \"num_pathways_per_instance\": 44\n",
    "    })\n",
    "    \n",
    "    config[\"resnet\"].update({\n",
    "        \"hidden_dim\": best_config[\"hidden_dim_resnet\"],\n",
    "        \"n_layers\": best_config[\"n_layers\"],\n",
    "        \"dropout\": best_config[\"dropout\"]\n",
    "    })\n",
    "    \n",
    "    config[\"optimizer\"].update({\n",
    "        \"learning_rate\": best_config[\"learning_rate\"],\n",
    "        \"clip_norm\": best_config[\"clip_norm\"],\n",
    "        \"batch_size\": best_config[\"batch_size\"]\n",
    "    })\n",
    "    \n",
    "    _, model = train_model(config, train_data, val_data, use_momentum=False)\n",
    "    \n",
    "    device = torch.device(config[\"env\"][\"device\"])\n",
    "    metrics = torchmetrics.MetricTracker(torchmetrics.MetricCollection({\n",
    "        \"R_cellwise_residuals\": torchmetrics.PearsonCorrCoef(num_outputs=1),\n",
    "        \"R_cellwise\": torchmetrics.PearsonCorrCoef(num_outputs=1),\n",
    "        \"MSE\": torchmetrics.MeanSquaredError()\n",
    "    }))\n",
    "    metrics.to(device)\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "        dataset=test_data, \n",
    "        batch_size=config[\"optimizer\"][\"batch_size\"],\n",
    "        shuffle=True, \n",
    "        drop_last=True, \n",
    "        collate_fn=custom_collate_fn  \n",
    "    )\n",
    "\n",
    "    final_metrics = evaluate_step(model, test_dataloader, metrics, device)\n",
    "    print(\"Final Test Metrics: \", final_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cfe888-453c-406d-94b6-634d8e5facd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN2",
   "language": "python",
   "name": "gnn2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
