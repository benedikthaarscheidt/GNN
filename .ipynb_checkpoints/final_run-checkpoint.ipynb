{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "327c5070-eab2-4bad-baab-9458ab879c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"scripts\")\n",
    "from functools import lru_cache\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import networkx as nx\n",
    "import scripts\n",
    "import torchmetrics\n",
    "from torch import nn\n",
    "import optuna\n",
    "import models\n",
    "\n",
    "from optuna.integration import TensorBoardCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f39fab7-2585-4105-a87b-9b115dfff2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=None)\n",
    "def get_data(n_fold=0, fp_radius=2):\n",
    "    def download_if_not_present(url, filepath):\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"File not found at {filepath}. Downloading...\")\n",
    "            response = requests.get(url, stream=True)\n",
    "            os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "            with open(filepath, \"wb\") as file:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    file.write(chunk)\n",
    "            print(\"Download completed.\")\n",
    "        else:\n",
    "            print(f\"File already exists at {filepath}.\")\n",
    "\n",
    "    # Download RNA-seq data\n",
    "    zip_url = \"https://cog.sanger.ac.uk/cmp/download/rnaseq_all_20220624.zip\"\n",
    "    zip_filepath = \"data/rnaseq.zip\"\n",
    "    rnaseq_filepath = \"data/rnaseq_normcount.csv\"\n",
    "    if not os.path.exists(rnaseq_filepath):\n",
    "        download_if_not_present(zip_url, zip_filepath)\n",
    "        with zipfile.ZipFile(zip_filepath, \"r\") as zipf:\n",
    "            zipf.extractall(\"data/\")\n",
    "    rnaseq = pd.read_csv(rnaseq_filepath, index_col=0)\n",
    "\n",
    "    # Load gene network, hierarchies, and driver genes\n",
    "    hierarchies = pd.read_csv(\"data/gene_to_pathway_final_with_hierarchy.csv\")\n",
    "    driver_genes = pd.read_csv(\"data/driver_genes_2.csv\").loc[:, \"gene\"].dropna()\n",
    "    gene_network = nx.read_edgelist(\"data/filtered_gene_network.edgelist\", nodetype=str)\n",
    "    ensembl_to_hgnc = dict(zip(hierarchies['Ensembl_ID'], hierarchies['HGNC']))\n",
    "    mapped_gene_network = nx.relabel_nodes(gene_network, ensembl_to_hgnc)\n",
    "\n",
    "    # Create edge tensors for the graph\n",
    "    edges_df = pd.DataFrame(\n",
    "        list(mapped_gene_network.edges(data=\"weight\")),\n",
    "        columns=[\"source\", \"target\", \"weight\"]\n",
    "    )\n",
    "    edges_df[\"weight\"] = edges_df[\"weight\"].fillna(1.0).astype(float)\n",
    "    valid_nodes = rnaseq.columns.intersection(hierarchies[\"HGNC\"])\n",
    "    filtered_edges = edges_df[edges_df[\"source\"].isin(valid_nodes) & edges_df[\"target\"].isin(valid_nodes)]\n",
    "    node_to_idx = {node: idx for idx, node in enumerate(valid_nodes)}\n",
    "    edge_index = torch.tensor(\n",
    "        filtered_edges[[\"source\", \"target\"]].replace(node_to_idx).values.T,\n",
    "        dtype=torch.long\n",
    "    )\n",
    "    edge_attr = torch.tensor(filtered_edges[\"weight\"].values, dtype=torch.float32)\n",
    "\n",
    "    # Prepare RNA-seq data for graph construction\n",
    "    driver_columns = rnaseq.columns.isin(driver_genes)\n",
    "    filtered_rna = rnaseq.loc[:, driver_columns]\n",
    "    pathway_dict = {gene: pathway.split(':')[1].split('[')[0].strip()\n",
    "                    for gene, pathway in zip(hierarchies[\"HGNC\"], hierarchies[\"Level_1\"])\n",
    "                    if isinstance(pathway, str)}\n",
    "    pathway_groups = {\n",
    "        pathway: torch.tensor([node_to_idx[gene] for gene in genes if gene in node_to_idx])\n",
    "        for pathway, genes in pathway_dict.items()\n",
    "    }\n",
    "\n",
    "    # Create cell-line graphs\n",
    "    tensor_exp = torch.tensor(filtered_rna.to_numpy())\n",
    "    cell_dict = {cell: Data(\n",
    "        x=tensor_exp[i].unsqueeze(1),\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "        y=None,\n",
    "        cell_line=cell\n",
    "    ) for i, cell in enumerate(filtered_rna.index)}\n",
    "\n",
    "    # Load drug data\n",
    "    smile_dict = pd.read_csv(\"data/smiles.csv\", index_col=0)\n",
    "    fp = scripts.FingerprintFeaturizer(R=fp_radius)\n",
    "    drug_dict = fp(smile_dict.iloc[:, 1], smile_dict.iloc[:, 0])\n",
    "\n",
    "    # Load IC50 data\n",
    "    data = pd.read_csv(\"data/GDSC1.csv\", index_col=0)\n",
    "    data = data.query(\"SANGER_MODEL_ID in @cell_dict.keys() & DRUG_ID in @drug_dict.keys()\")\n",
    "\n",
    "    # Split data into folds\n",
    "    unique_cell_lines = data[\"SANGER_MODEL_ID\"].unique()\n",
    "    np.random.seed(420)\n",
    "    np.random.shuffle(unique_cell_lines)\n",
    "    folds = np.array_split(unique_cell_lines, 10)\n",
    "    train_idxs = list(range(10))\n",
    "    train_idxs.remove(n_fold)\n",
    "    validation_idx = np.random.choice(train_idxs)\n",
    "    train_idxs.remove(validation_idx)\n",
    "    train_lines = np.concatenate([folds[idx] for idx in train_idxs])\n",
    "    validation_lines = folds[validation_idx]\n",
    "    test_lines = folds[n_fold]\n",
    "\n",
    "    train_data = data.query(\"SANGER_MODEL_ID in @train_lines\")\n",
    "    validation_data = data.query(\"SANGER_MODEL_ID in @validation_lines\")\n",
    "    test_data = data.query(\"SANGER_MODEL_ID in @test_lines\")\n",
    "\n",
    "    # Build datasets\n",
    "    train_dataset = scripts.OmicsDataset(cell_dict, drug_dict, train_data)\n",
    "    validation_dataset = scripts.OmicsDataset(cell_dict, drug_dict, validation_data)\n",
    "    test_dataset = scripts.OmicsDataset(cell_dict, drug_dict, test_data)\n",
    "\n",
    "    return train_dataset, validation_dataset, test_dataset, pathway_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93db7a6f-24d4-48e7-8dc9-9ae4b4d0448b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_852508/3692979905.py:42: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  filtered_edges[[\"source\", \"target\"]].replace(node_to_idx).values.T,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'scripts' has no attribute 'FingerprintFeaturizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_data, val_data, test_data, pathway_groups\u001b[38;5;241m=\u001b[39mget_data(\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 70\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(n_fold, fp_radius)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Load drug data\u001b[39;00m\n\u001b[1;32m     69\u001b[0m smile_dict \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/smiles.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 70\u001b[0m fp \u001b[38;5;241m=\u001b[39m scripts\u001b[38;5;241m.\u001b[39mFingerprintFeaturizer(R\u001b[38;5;241m=\u001b[39mfp_radius)\n\u001b[1;32m     71\u001b[0m drug_dict \u001b[38;5;241m=\u001b[39m fp(smile_dict\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m], smile_dict\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Load IC50 data\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'scripts' has no attribute 'FingerprintFeaturizer'"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data, pathway_groups=get_data(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dad465-d12c-438c-9204-29458ddca7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"gnn\": {\n",
    "        \"input_dim\": 100,  # Number of node features\n",
    "        \"hidden_dim\": 128,  # Hidden dimension for GNN layers\n",
    "        \"output_dim\": 128,  # Output dimension of GNN\n",
    "        \"pathway_groups\": pathway_groups,  # Pathway groups from your data\n",
    "        \"layer_modes\": [False, False, True],  # Pathway-specific message passing in the last layer\n",
    "        \"pooling_mode\": \"pathway\",  # Use pathway-specific pooling\n",
    "        \"aggr_modes\": [\"sum\", \"sum\", \"sum\"],  # Aggregation types for GNN layers\n",
    "    },\n",
    "    \"drug\": {\n",
    "        \"input_dim\": 256,  # Dimension of raw drug features\n",
    "        \"embed_dim\": 128,  # Embedding dimension (must match GNN output)\n",
    "    },\n",
    "    \"resnet\": {\n",
    "        \"hidden_dim\": 1024,  # Hidden dimension of ResNet layers\n",
    "        \"n_layers\": 6,  # Number of ResNet layers\n",
    "        \"dropout\": 0.1,  # Dropout rate\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"learning_rate\": 1e-3,  # Learning rate\n",
    "        \"batch_size\": 32,  # Batch size\n",
    "        \"clip_norm\": 1.0,  # Gradient clipping norm\n",
    "        \"stopping_patience\": 10,  # Patience for early stopping\n",
    "        \"use_momentum\": True,  # Use momentum in optimization\n",
    "    },\n",
    "    \"env\": {\n",
    "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",  # Use GPU if available\n",
    "        \"max_epochs\": 50,  # Maximum number of epochs\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aecbf01f-4c3b-42fb-8be4-a754fb83c7df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ModularGNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gnn_model \u001b[38;5;241m=\u001b[39m ModularGNN(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgnn\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      2\u001b[0m drug_mlp \u001b[38;5;241m=\u001b[39m DrugMLP(input_dim\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrug\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m], embed_dim\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrug\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membed_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m resnet \u001b[38;5;241m=\u001b[39m ResNet(embed_dim\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrug\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membed_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m], hidden_dim\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m      4\u001b[0m                 n_layers\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m], dropout\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ModularGNN' is not defined"
     ]
    }
   ],
   "source": [
    "gnn_model = ModularGNN(**config[\"gnn\"])\n",
    "drug_mlp = DrugMLP(input_dim=config[\"drug\"][\"input_dim\"], embed_dim=config[\"drug\"][\"embed_dim\"])\n",
    "resnet = ResNet(embed_dim=config[\"drug\"][\"embed_dim\"], hidden_dim=config[\"resnet\"][\"hidden_dim\"], \n",
    "                n_layers=config[\"resnet\"][\"n_layers\"], dropout=config[\"resnet\"][\"dropout\"])\n",
    "\n",
    "# Create the combined model\n",
    "combined_model = CombinedModel(gnn=gnn_model, drug_mlp=drug_mlp, resnet=resnet)\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device(config[\"env\"][\"device\"])\n",
    "combined_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0571bf3d-7529-49e6-a989-8314f79ee1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming train_data is a PyTorch dataset\n",
    "single_instance = train_data[0]  # Extract the first instance\n",
    "\n",
    "# Unpack the instance\n",
    "cell_graph, drug_vector, target_value = single_instance\n",
    "\n",
    "# Move data to the appropriate device\n",
    "cell_graph = cell_graph.to(device)\n",
    "drug_vector = drug_vector.to(device)\n",
    "\n",
    "# Forward pass through the model\n",
    "with torch.no_grad():\n",
    "    output = combined_model(cell_graph, drug_vector)\n",
    "\n",
    "# Print the result\n",
    "print(\"Predicted output:\", output.item())\n",
    "print(\"True target value:\", target_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN2",
   "language": "python",
   "name": "gnn2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
