{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28ef7cdb-7fdf-4a76-b46f-c742b0bcb014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append(r\"scripts\")\n",
    "from model import ModularPathwayConv, ModularGNN\n",
    "torch.set_printoptions(threshold=torch.inf)\n",
    "from torch_geometric.loader import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3375c36-291a-4d3e-9559-df17fcab9b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=None)\n",
    "def get_data(n_fold=0, fp_radius=2):\n",
    "    import math\n",
    "\n",
    "    def download_if_not_present(url, filepath):\n",
    "        \"\"\"\n",
    "        Downloads a file from a URL if it does not already exist locally.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"File not found at {filepath}. Downloading...\")\n",
    "            response = requests.get(url, stream=True)\n",
    "            os.makedirs(os.path.dirname(filepath), exist_ok=True)  # Ensure the directory exists\n",
    "            with open(filepath, \"wb\") as file:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    file.write(chunk)\n",
    "            print(\"Download completed.\")\n",
    "        else:\n",
    "            print(f\"File already exists at {filepath}.\")\n",
    "\n",
    "    # Download RNA-seq data if not present\n",
    "    zip_url = \"https://cog.sanger.ac.uk/cmp/download/rnaseq_all_20220624.zip\"\n",
    "    zip_filepath = \"data/rnaseq.zip\"\n",
    "    rnaseq_filepath = \"data/rnaseq_normcount.csv\"\n",
    "    extraction_path = \"data/\"\n",
    "    \n",
    "        # Check if the RNA-seq file already exists\n",
    "    if not os.path.exists(rnaseq_filepath):\n",
    "        print(f\"RNA-seq file not found at {rnaseq_filepath}. Checking for ZIP file...\")\n",
    "        \n",
    "        # Step 1: Download the ZIP file if it is not already present\n",
    "        download_if_not_present(zip_url, zip_filepath)\n",
    "    \n",
    "        # Step 2: Extract the ZIP file\n",
    "        if os.path.exists(zip_filepath):\n",
    "            print(\"Extracting the ZIP file...\")\n",
    "            with zipfile.ZipFile(zip_filepath, \"r\") as zipf:\n",
    "                zipf.extractall(extraction_path)\n",
    "                print(\"Extraction completed.\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"ZIP file not found at {zip_filepath}. Could not extract RNA-seq data.\")\n",
    "    \n",
    "    # Load RNA-seq data\n",
    "    if os.path.exists(rnaseq_filepath):\n",
    "        rnaseq = pd.read_csv(rnaseq_filepath, index_col=0)\n",
    "        print(\"RNA-seq CSV file loaded successfully.\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"RNA-seq file not found at {rnaseq_filepath} after extraction.\")\n",
    "\n",
    "\n",
    "    # Load driver genes and hierarchies\n",
    "    hierarchies = pd.read_csv(\"data/gene_to_pathway_final_with_hierarchy.csv\")\n",
    "    driver_genes = pd.read_csv(\"data/driver_genes_2.csv\")\n",
    "\n",
    "    # Load the gene network\n",
    "    gene_network = nx.read_edgelist(\n",
    "        r\"data/filtered_gene_network.edgelist\",\n",
    "        nodetype=str\n",
    "    )\n",
    "\n",
    "    # Create a dictionary mapping from Ensembl_ID to HGNC\n",
    "    ensembl_to_hgnc = dict(zip(hierarchies['Ensembl_ID'], hierarchies['HGNC']))\n",
    "\n",
    "    # Relabel nodes in the graph\n",
    "    mapped_gene_network = nx.relabel_nodes(gene_network, ensembl_to_hgnc)\n",
    "\n",
    "    # Convert the graph edges to a DataFrame\n",
    "    edges_df = pd.DataFrame(\n",
    "        list(mapped_gene_network.edges(data=\"weight\")),\n",
    "        columns=[\"source\", \"target\", \"weight\"]\n",
    "    )\n",
    "    \n",
    "    # Ensure the weight column is numeric\n",
    "    edges_df[\"weight\"] = edges_df[\"weight\"].fillna(1.0).astype(float)\n",
    "\n",
    "    # Filter RNA-seq data for driver genes\n",
    "    driver_columns = rnaseq.columns.isin(hierarchies[\"HGNC\"])\n",
    "    filtered_rna = rnaseq.loc[:, driver_columns]\n",
    "    tensor_exp = torch.Tensor(filtered_rna.to_numpy())\n",
    "\n",
    "    # Create a dictionary mapping cell lines to their expression tensors\n",
    "    cell_dict = {cell: tensor_exp[i] for i, cell in enumerate(filtered_rna.index.to_numpy())}\n",
    "\n",
    "    # Get the set of valid nodes (columns in filtered RNA)\n",
    "    valid_nodes = set(filtered_rna.columns)\n",
    "\n",
    "    # Filter edges for valid nodes\n",
    "    filtered_edges = edges_df[\n",
    "        (edges_df[\"source\"].isin(valid_nodes)) & (edges_df[\"target\"].isin(valid_nodes))\n",
    "    ]\n",
    "\n",
    "    # Map nodes to numeric indices\n",
    "    node_to_idx = {node: idx for idx, node in enumerate(valid_nodes)}\n",
    "    filtered_edges[\"source_idx\"] = filtered_edges[\"source\"].map(node_to_idx)\n",
    "    filtered_edges[\"target_idx\"] = filtered_edges[\"target\"].map(node_to_idx)\n",
    "\n",
    "    # Create PyTorch edge tensors\n",
    "    edge_index = torch.tensor(\n",
    "        filtered_edges[[\"source_idx\", \"target_idx\"]].values,\n",
    "        dtype=torch.long\n",
    "    ).T\n",
    "    edge_attr = torch.tensor(\n",
    "        filtered_edges[\"weight\"].values,\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    # Filter edges for valid nodes\n",
    "    filtered_hierarchy = hierarchies[\n",
    "        (hierarchies[\"HGNC\"].isin(valid_nodes))\n",
    "    ]\n",
    "    # Step 1: Setup the initial pathway_dict\n",
    "    pathway_dict = {\n",
    "        gene: pathway.split(':', 1)[1].split('[', 1)[0].strip() if isinstance(pathway, str) and ':' in pathway else None\n",
    "        for gene, pathway in dict(zip(filtered_hierarchy['HGNC'], filtered_hierarchy['Level_1'])).items()\n",
    "    }\n",
    "\n",
    "    # Step 2: Process the pathway_dict (group genes by pathway)\n",
    "    grouped_pathway_dict = {}\n",
    "    for gene, pathway in pathway_dict.items():\n",
    "        if pathway:  # Ignore genes without valid pathways\n",
    "            grouped_pathway_dict.setdefault(pathway, []).append(gene)\n",
    "\n",
    "    # Step 3: Map pathways to numeric indices\n",
    "    pathway_groups = {\n",
    "        pathway: [node_to_idx[gene] for gene in genes if gene in node_to_idx]\n",
    "        for pathway, genes in grouped_pathway_dict.items()\n",
    "    }\n",
    "\n",
    "    # Step 4: Convert pathway_groups to PyTorch Tensors\n",
    "    pathway_tensors = {\n",
    "        pathway: torch.tensor(nodes, dtype=torch.long) for pathway, nodes in pathway_groups.items()\n",
    "    }\n",
    "\n",
    "    # Create PyTorch Geometric Data objects for each cell line\n",
    "    graph_data_list = []\n",
    "    for cell, x in cell_dict.items():\n",
    "        # Transform x to have shape [num_nodes, num_features]\n",
    "        if x.ndim == 2 and x.shape[0] == 1:  # [1, num_nodes]\n",
    "            x = x.T\n",
    "        elif x.ndim == 1:  # [num_nodes]\n",
    "            x = x.unsqueeze(1)\n",
    "\n",
    "        graph_data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "        graph_data.y = None\n",
    "        graph_data.cell_line = cell\n",
    "        graph_data_list.append(graph_data)\n",
    "\n",
    "    # Load drug response data and filter missing cell lines\n",
    "    data = pd.read_csv(\"data/GDSC1.csv\", index_col=0)\n",
    "    data = data.query(\"SANGER_MODEL_ID in @cell_dict.keys()\")\n",
    "\n",
    "    # Split cell lines into folds for training/validation/testing\n",
    "    unique_cell_lines = data[\"SANGER_MODEL_ID\"].unique()\n",
    "    np.random.seed(420)  # Ensure reproducibility\n",
    "    np.random.shuffle(unique_cell_lines)\n",
    "    folds = np.array_split(unique_cell_lines, 10)\n",
    "    test_lines = folds[n_fold]\n",
    "    train_idxs = list(range(10))\n",
    "    train_idxs.remove(n_fold)\n",
    "    validation_idx = np.random.choice(train_idxs)\n",
    "    train_idxs.remove(validation_idx)\n",
    "    train_lines = np.concatenate([folds[idx] for idx in train_idxs])\n",
    "    validation_lines = folds[validation_idx]\n",
    "    test_lines = folds[n_fold]\n",
    "\n",
    "    # Split the drug response data\n",
    "    train_data = data.query(\"SANGER_MODEL_ID in @train_lines\")\n",
    "    validation_data = data.query(\"SANGER_MODEL_ID in @validation_lines\")\n",
    "    test_data = data.query(\"SANGER_MODEL_ID in @test_lines\")\n",
    "\n",
    "    # Create datasets for training, validation, and testing\n",
    "    train_graphs = [graph for graph in graph_data_list if graph.cell_line in train_lines]\n",
    "    val_graphs = [graph for graph in graph_data_list if graph.cell_line in validation_lines]\n",
    "    test_graphs = [graph for graph in graph_data_list if graph.cell_line in test_lines]\n",
    "\n",
    "    # Check if filtered edges still reference valid nodes\n",
    "    invalid_source_nodes = filtered_edges[~filtered_edges[\"source\"].isin(valid_nodes)]\n",
    "    invalid_target_nodes = filtered_edges[~filtered_edges[\"target\"].isin(valid_nodes)]\n",
    "    \n",
    "    if not invalid_source_nodes.empty or not invalid_target_nodes.empty:\n",
    "        print(f\"Invalid source nodes: {invalid_source_nodes}\")\n",
    "        print(f\"Invalid target nodes: {invalid_target_nodes}\")\n",
    "        raise ValueError(\"Edges reference nodes not in valid_nodes.\")\n",
    "\n",
    "    return train_graphs, val_graphs, test_graphs, pathway_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6194c2e-e218-4089-931e-0208470ee7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNA-seq CSV file loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_621753/2596222321.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_edges[\"source_idx\"] = filtered_edges[\"source\"].map(node_to_idx)\n",
      "/tmp/ipykernel_621753/2596222321.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_edges[\"target_idx\"] = filtered_edges[\"target\"].map(node_to_idx)\n"
     ]
    }
   ],
   "source": [
    "train_graphs, val_graphs, test_graphs, pathway_tensors = get_data(n_fold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b0c2da6-a1ef-4360-a518-c26c80038c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_modes = [True, True, True]  #this is to specify wehter you want pathway specific message aggregation or global (if there is an edge between two nodes it will send) Example: Global (false), Pathway(true), Pathway \n",
    "pooling_mode = 'none'       # Example: No pooling. This needs refinement still and probably doesnt work yet\n",
    "aggr_modes = ['sum', 'sum', 'sum']#when chose pathway specific message aggregation then this is the method how multiple messages for one tagret node get aggregated\n",
    "hidden_dim = 16     \n",
    "model = ModularGNN(\n",
    "    input_dim=train_graphs[0].x.shape[1],  # Number of input features per node\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=train_graphs[0].x.shape[1],  # Number of output features per node\n",
    "    pathway_groups=pathway_tensors,\n",
    "    layer_modes=layer_modes,\n",
    "    aggr_modes=aggr_modes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ff46b11-d884-4eed-a329-79137fa9dc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next layer\n",
      "next layer\n",
      "next layer\n",
      "Output shape: torch.Size([7813, 1])\n"
     ]
    }
   ],
   "source": [
    "example_graph = train_graphs[0]\n",
    "out = model(\n",
    "    x=example_graph.x,  # Node features\n",
    "    edge_index=example_graph.edge_index,  # Edge indices\n",
    "    edge_attr=example_graph.edge_attr if 'edge_attr' in example_graph else None  # Edge attributes (if available)\n",
    ")\n",
    "print(\"Output shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7729219-7978-495e-85b6-7aaa113be38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next layer\n",
      "next layer\n",
      "next layer\n",
      "Batch output shape: torch.Size([31252, 1])\n",
      "next layer\n",
      "next layer\n",
      "next layer\n",
      "Batch output shape: torch.Size([31252, 1])\n",
      "next layer\n",
      "next layer\n",
      "next layer\n",
      "Batch output shape: torch.Size([31252, 1])\n",
      "next layer\n",
      "next layer\n",
      "next layer\n",
      "Batch output shape: torch.Size([31252, 1])\n",
      "next layer\n",
      "next layer\n",
      "next layer\n",
      "Batch output shape: torch.Size([31252, 1])\n",
      "next layer\n",
      "next layer\n",
      "next layer\n",
      "Batch output shape: torch.Size([31252, 1])\n",
      "next layer\n",
      "next layer\n",
      "next layer\n",
      "Batch output shape: torch.Size([31252, 1])\n",
      "next layer\n",
      "next layer\n",
      "next layer\n",
      "Batch output shape: torch.Size([31252, 1])\n",
      "next layer\n",
      "next layer\n",
      "next layer\n",
      "Batch output shape: torch.Size([31252, 1])\n",
      "next layer\n",
      "next layer\n",
      "next layer\n",
      "Batch output shape: torch.Size([31252, 1])\n",
      "next layer\n",
      "next layer\n",
      "next layer\n",
      "Batch output shape: torch.Size([31252, 1])\n",
      "next layer\n",
      "next layer\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_graphs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m----> 5\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(\n\u001b[1;32m      6\u001b[0m         x\u001b[38;5;241m=\u001b[39mbatch\u001b[38;5;241m.\u001b[39mx,\n\u001b[1;32m      7\u001b[0m         edge_index\u001b[38;5;241m=\u001b[39mbatch\u001b[38;5;241m.\u001b[39medge_index,\n\u001b[1;32m      8\u001b[0m         edge_attr\u001b[38;5;241m=\u001b[39mbatch\u001b[38;5;241m.\u001b[39medge_attr \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_attr\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batch \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch output shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, out\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/work/haarscheid/.conda/envs/GNN2/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/work/haarscheid/.conda/envs/GNN2/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/work/haarscheid/cancer_baseline2/cancer_baseline/Graphs/scripts/model.py:217\u001b[0m, in \u001b[0;36mModularGNN.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# Process layers\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[0;32m--> 217\u001b[0m     x \u001b[38;5;241m=\u001b[39m layer(x, edge_index, edge_attr\u001b[38;5;241m=\u001b[39medge_attr, pathway_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_modes[i])\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# Handle different pooling modes\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooling_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/work/haarscheid/.conda/envs/GNN2/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/work/haarscheid/.conda/envs/GNN2/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/work/haarscheid/cancer_baseline2/cancer_baseline/Graphs/scripts/model.py:55\u001b[0m, in \u001b[0;36mModularPathwayConv.forward\u001b[0;34m(self, x, edge_index, edge_attr, pathway_mode)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Handle edge attributes if available\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge_attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# Filter the original edge_attr based on the valid_mask for the original edge_index\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     edge_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39misin(edge_index[\u001b[38;5;241m0\u001b[39m], nodes) \u001b[38;5;241m&\u001b[39m torch\u001b[38;5;241m.\u001b[39misin(edge_index[\u001b[38;5;241m1\u001b[39m], nodes)\n\u001b[1;32m     56\u001b[0m     sub_edge_attr \u001b[38;5;241m=\u001b[39m edge_attr[edge_mask]  \n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for batch in train_loader:\n",
    "    out = model(\n",
    "        x=batch.x,\n",
    "        edge_index=batch.edge_index,\n",
    "        edge_attr=batch.edge_attr if 'edge_attr' in batch else None\n",
    "    )\n",
    "    print(\"Batch output shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f417f002-f1d5-4cba-b6af-a74b56cc25b0",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN2",
   "language": "python",
   "name": "gnn2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
